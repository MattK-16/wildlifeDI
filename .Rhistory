data(mockhunt)
head(mockhunt)
ggplot(data=mockhunt, aes(x=dt_lev, y=dist, group=phaid)) +
geom_line(col='grey32') +
labs(x='Time to contact (min)',y='Step-length (m)') +
scale_x_discrete(labels=c(as.character(seq(-96,96,by=8))))
ggplot(data=mockhunt, aes(x=dt_lev, y=displacement, group=phaid)) +
geom_line(col='grey32') +
labs(x='Time to contact (min)',y='Displacement (m)') +
scale_x_discrete(labels=c(as.character(seq(-96,96,by=8))))
ggplot(data=mockhunt, aes(x=dt_lev, y=Forest_Perc, group=phaid)) +
geom_line(col='grey32') +
labs(x='Time to contact (min)',y='Forest Cover (%)') +
scale_x_discrete(labels=c(as.character(seq(-96,96,by=8))))
ggplot(mockhunt, aes(x=dt_lev, y=dist)) +
geom_boxplot() +
coord_cartesian(ylim=c(0,1000)) +
labs(x='Time to contact (min)',y='Step length (m)') +
scale_x_discrete(labels=c(as.character(seq(-96,96,by=8))))
ggplot(mockhunt, aes(x=dt_lev, y=displacement)) +
geom_boxplot() +
coord_cartesian(ylim=c(0,2000)) +
labs(x='Time to contact (min)',y='Distance to contact (m)') +
scale_x_discrete(labels=c(as.character(seq(-96,96,by=8))))
ggplot(mockhunt, aes(x=dt_lev, y=Forest_Perc)) +
geom_boxplot() +
labs(x='Time to contact (min)',y='Forest Cover (%)') +
scale_x_discrete(labels=c(as.character(seq(-96,96,by=8))))
head(mockhunt)
# NOT RUN
mca <- conProcess(deer,hunters,dc=150,tc=4*60) # process contacts, tc=4 min, dc=150m
## MOCK HUNT DATA FOR PACKAGE
#devtools::load_all('D:/RPackages/wildlifeDI/wildlifeDI/')
library(wildlifeDI)
library(adehabitatLT)
#------------------------------------
#Read in and format the male deer data.
#------------------------------------
deerdf <- read.csv('D:/Mobility/Noble_Deer/Data/OSWALT_Data/GPS Data/Oswalt_Ranch_2008_2009_Master_Database_2_21_2014.csv',stringsAsFactors=F)
deerdf$POSIX <- as.POSIXct(strptime(paste(deerdf$Year,"/",deerdf$Month,"/",deerdf$Day," ",deerdf$Hour,":",deerdf$Minute,":",deerdf$Seconds,sep=""),"%Y/%m/%d %H:%M:%S"),tz='CST6CDT')
deerdf$ID2 <- paste(deerdf$StudyYr,'_',deerdf$ID,sep='')
#-------------------------------
#Read in the Mock hunter data
#-------------------------------
huntdf <- read.csv('D:/Mobility/Noble_Deer/HuntDeer/Data/Mock_Hunts/JedProcessed/MockHunt_ALL.csv',stringsAsFactors=F)
huntdf$POSIX <-  as.POSIXct(strptime(huntdf$date,"%m/%d/%Y %I:%M:%S %p"),tz='CST6CDT')
#check for duplicate fixes (times) adn NA's
for (i in unique(huntdf$ID)){
ind <- which(huntdf$ID == i)
#check for duplicate fixes (times)
ind1 <- duplicated(huntdf$POSIX[ind])
io <- ind[ind1]
if(length(io)>0)
huntdf <- huntdf[-io,]
}
#REMOVE ANY NA times.
huntdf <- huntdf[-which(is.na(huntdf$POSIX)),]
#Create multiple ltraj databases
mtraj1 <- as.ltraj(deerdf[,c('X','Y')],deerdf$POSIX,id=factor(deerdf$ID),burst=factor(deerdf$ID2),infolocs=deerdf)
mtraj2 <- as.ltraj(huntdf[,c('x','y')],huntdf$POSIX,id=factor(huntdf$ID),burst=factor(huntdf$ID),infolocs=huntdf)
#Use only hunting season for deer
lim <- as.POSIXct(strptime(c("09/11/2008", "14/12/2008"),"%d/%m/%Y", tz='CST6CDT'))
mtraj2008 <- gdltraj(mtraj1, min = lim[1],max = lim[2], type="POSIXct")
lim <- as.POSIXct(strptime(c("08/11/2009", "13/12/2009"),"%d/%m/%Y", tz='CST6CDT'))
mtraj2009 <- gdltraj(mtraj1, min = lim[1],max = lim[2], type="POSIXct")
#Get appropriate dates for MockHunt analysis
lim <- as.POSIXct(strptime(c("01/12/2008", "25/12/2008"),"%d/%m/%Y", tz='CST6CDT'))
mtrajmh08 <- gdltraj(mtraj1, min = lim[1],max = lim[2], type="POSIXct")
lim <- as.POSIXct(strptime(c("01/12/2009", "25/12/2009"),"%d/%m/%Y", tz='CST6CDT'))
mtrajmh09 <- gdltraj(mtraj1, min = lim[1],max = lim[2], type="POSIXct")
mtrajdeer <- c(mtrajmh08,mtrajmh09)
tc <- 4*60    #temporal threshold based on 8 min fix interval
dc <- 150     #Choose biologically relevant dc
#Main contact processing script
mca <- conProcess(mtrajdeer,mtraj2,dc=dc,tc=tc) #~ 15min
#Group into phases
mcp <- conPhase(mca,pc=16*60)
conSummary(mcp)
# Study displacement from contacts
mcp <- conDisplacement(mcp,def='first')
#Context Analysis
vars <- c('x','y','dist','displacement','Forest_Perc')
mockhunt <- conContext(mcp,var=vars,def='first',nlag=12,lag=8*60,gap=4*60,idcol='burst',nrand=0)
save(mockhunt, file='D:/RPackages/wildlifeDI/mockhunt.RData',compress='xz')
head(mockhunt)
install.packages('changepoint')
library(changepoint)
levels(dt_lev)
levels(mockhunt$dt_lev)
?order
mockhunt = mockhunt[
with(mockhunt, order(phaid,dt_lev)),
]
head(mockhunt)
summary(mockhunt)
summary(mockhunt$dt_lev)
mockhunt$t = as.numeric(levels(mockhunt$dt_lev))[mockhunt$dt_lev]
head(mockhunt)
mockhunt$t = as.integer(mockhunt$dt_lev)
head(mockhunt)
head(mockhunt,24)
i = 1
d
ts = subset(mockhunt,phaid == i)
cp_sl = cpt.mean(ts$dist)
cp_sl
outdf = data.frame(phaid = unique(mockhunt$phaid),cp_sl = 0,cp_disp = 0,cp_for = 0)
mockhunt$t = as.integer(mockhunt$dt_lev)
for (i in mockhunt$phaid){
ts = subset(mockhunt,phaid == i)
outdf$cp_sl[i] = cpt.mean(ts$dist)
outdf$cp_disp[i] = cpt.mean(ts$displacement)
outdf$cp_for[i] = cpt.mean(ts$Forest_Perc)
}
cp_sl
?cpt.mean
outdf$cp_sl[i] = cpt.mean(ts$dist,class=FALSE)
outdf$cp_sl[i] = cpt.mean(ts$dist,class=FALSE)$cpt
cpt.mean(ts$dist,class=FALSE)
outdf = data.frame(phaid = unique(mockhunt$phaid),cp_sl = 0,cp_disp = 0,cp_for = 0)
mockhunt$t = as.integer(mockhunt$dt_lev)
for (i in mockhunt$phaid){
ts = subset(mockhunt,phaid == i)
outdf$cp_sl[i] = cpt.mean(ts$dist,class=FALSE)[1]
outdf$cp_disp[i] = cpt.mean(ts$displacement,class=F)[1]
outdf$cp_for[i] = cpt.mean(ts$Forest_Perc,class=F)[1]
}
mockhunt$t = as.integer(mockhunt$dt_lev)
mockhunt$con = 0
mochunt$con[which(mockhunt$t > 12)] = 1
mockhunt$con[which(mockhunt$t > 12)] = 1
glmmTMB <- glmmTMB(dist ~ t*con + (1|f) + ar1(t-1|f), data=mockhunt,family=gaussian)
testglmm <- glmmTMB(dist ~ t*con + (1|phaid) + ar1(t-1|phaid), data=mockhunt,family=gaussian)
?mockhunt
View(mockhunt)
testglmm <- glmmTMB(dist ~ t*con + (1|ID) + ar1(t-1|ID), data=mockhunt,family=gaussian)
vignette('troubleshooting')
testglmm <- glmmTMB(log(dist) ~ t*con + (1|ID) + ar1(t-1|ID), data=mockhunt,family=gaussian)
testglmm <- glmmTMB(log(dist) ~ t*con + (1|ID) + ar1(t-1|ID), data=mockhunt,family=gaussian)
summary(testglmm)
testglmm <- glmmTMB(dist ~ t*con + (1|ID) + ar1(t-1|ID), data=mockhunt,family=gaussian)
summary(testglmm)
?lme
testlme <- lme(dist ~ t*con (1), data = mockhunt, random = ~1|phaid)
?lme
library(nlme)
testlme <- lme(dist ~ t*con (1), random = ~t|phaid, data = mockhunt)
testlme <- lme(dist ~ t*con, random = ~ t|phaid, data = mockhunt)
testlme <- lme(dist ~ t*con, random = ~ 1|phaid, data = mockhunt)
testlme <- lme(dist ~ t*con, random = ~ 1|phaid, data = mockhunt)
summary(mockhunt$dist)
mh = mockhunt[!is.na(mockhunt$dist),]
testlme <- lme(dist ~ t*con, random = ~ 1|phaid, data = mh)
summary(testlme)
testlme <- lme(dist ~ t*con, random = ~ t|phaid, data = mh)
summary(testlme)
update(testlme,correlation=corAR1())
testlme <- lme(dist ~ t*con, random = ~ 1|phaid, data = mh)
update(testlme,correlation=corAR1())
testlme <- lme(dist ~ t*con, random = ~ 1|phaid, data = mh)
t2 = update(testlme,correlation=corAR1())
summary(t2)
displme <- lme(displacement ~ t*con , random = ~ 1|phaid, correlation=corAR1,data = mh)
distlme <- lme(dist ~ t*con , random = ~ 1|phaid, correlation=corAR1(),data = mh)
summary(distlme)
displme <- lme(displacement ~ t*con , random = ~ 1|phaid, correlation=corAR1(),data = mh)
summary(displme)
pForlme <- lme(Forest_Perc ~ t*con , random = ~ 1|phaid, correlation=corAR1(),data = mh)
summary(pForlme)
distlme <- lme(dist ~ t*con , random = ~ 1|ID, correlation=corAR1(),data = mh)
summary(distlme)
pForlme <- lme(Forest_Perc ~ t*con , random = ~ 1|ID, correlation=corAR1(),data = mh)
summary(pForlme)
m1 = lme(pForest ~ dt_lev random = ~1|ID, data = doe_rand)
m1 = lme(pForest ~ dt_lev,random = ~1|ID, data = doe_rand)
summary(m1)
tapply(doe_rand$dist, doe_rand$dt_lev, summary)
tapply(doe_rand$pForest, doe_rand$dt_lev, summary)
tapply(doe_rand$dist, doe_rand$dt_lev, c(mean,sd))
tapply(doe_rand$dist, doe_rand$dt_lev, mean)
tapply(doe_rand$dist, doe_rand$dt_lev, sd)
tapply(doe_rand$pForest, doe_rand$dt_lev, mean)
tapply(doe_rand$pForest, doe_rand$dt_lev, sd)
m1 = lme(pForest ~ dt_lev,random = ~1|ID, data = doe_rand)
summary(m1)
m2 = lme(dist ~ dt_lev, random= ~1|ID, data = doe_rand)
summary(m2)
mockhunt$t = as.integer(mockhunt$dt_lev)
mockhunt$con = 0
mockhunt$con[which(mockhunt$t > 12)] = 1
mh = mockhunt[!is.na(mockhunt$dist),]
distlme <- lme(dist ~ t*con , random = ~ 1|ID, correlation=corAR1(),data = mh)
summary(distlme)
displme <- lme(displacement ~ t*con , random = ~ 1|ID, correlation=corAR1(),data = mh)
summary(displme)
-26.9+73.5
displme <- lme(displacement ~ t*con , random = ~ 1|ID, correlation=corAR1(),data = mh)
summary(displme)
displme2 <- lme(displacement ~ t*con , random = ~ 1|ID,data = mh)
summary(displme2)
distlme <- lme(dist ~ t*con , random = ~ 1|ID, correlation=corAR1(),data = mh)
summary(distlme)
distlme2 <- lme(dist ~ t*con , random = ~ 1|ID,data = mh)
summary(distlme2)
### Cacheing data for speed
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
#library(wildlifeDI)
library(adehabitatLT)
library(ggplot2)
library(sf)
library(igraph)
library(nlme)
#devtools::load_all('D:/RPackages/wildlifeDI/wildlifeDI/R/')
devtools::install_github('jedalong/wildlifeDI')
#devtools::load_all('D:/RPackages/wildlifeDI/wildlifeDI/R/')
#devtools::install_github('jedalong/wildlifeDI')
library(wildlifeDI)
data(does)
does
plot(does)
?sample
library(spatstat)
install.packages('spatstat')
devtools::install_github('jedalong/wildlifeDI')
library(wildlifeDI)
?conMatrix
### Cacheing data for speed
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
library(wildlifeDI)
library(adehabitatLT)
library(ggplot2)
library(sf)
library(igraph)
library(nlme)
data(does)
does
plot(does)
plt <- dcPlot(does,tc=15*60,dmax=1000)
plt
doecons <- conProcess(does,dc=50,tc=15*60)
doephas <- conPhase(doecons, pc=60*60)
conSummary(doephas)
doepair <- conPairs(doephas)
doetemp <- conTemporal(doephas,units='mins')
doepair$hod <- as.POSIXlt(doepair$date)$hour + as.POSIXlt(doepair$date)$min / 60  #convert POSIX to hours
doetemp$hod <- as.POSIXlt(doetemp$start_time)$hour + as.POSIXlt(doetemp$start_time)$min / 60  #convert POSIX to hours
doepair$dom <- as.POSIXlt(doepair$date)$mday
hist(doepair$dom,breaks=0:31)
hist(doepair$hod,breaks=0:24) #Figure 2b
hist(doetemp$hod,breaks=0:24) #Figure 2c
hist(as.numeric(doetemp$duration)) #figure 2d
con_sf <- conSpatial(doephas,type='point')             # Get points of all contacts
#Figure 3a
sf_pt <- ltraj2sf(does)  # Turn all fixes into sf points
plot(st_geometry(sf_pt),col='grey',pch=20)
plot(st_geometry(con_sf),col='black',pch=20,add=T)
#Figure 3b
con_sf_first <- conSpatial(doephas,type='point',def='first')
plot(st_geometry(sf_pt),col='grey',pch=20)
plot(st_geometry(con_sf),col='black',pch=20,add=T)
plot(st_geometry(con_sf_first),col='red',pch=20,add=T)
#Figure 3c
con_sf_ln <- conSpatial(doephas,type='line')
sf_ln <- ltraj2sf(does,type='line')  # Turn all fixes into sf points
plot(st_geometry(sf_ln),col='grey')
plot(st_geometry(con_sf_ln),col='red',add=T)
mat_cnt <- conMatrix(doecons)
#mat_rat <- conMatrix(doecons,output='rate')
mat_cnt
#shorten ID names
row.names(mat_cnt) <- substr(row.names(mat_cnt),5,6)
colnames(mat_cnt) <- substr(colnames(mat_cnt),5,6)
gr <- graph_from_adjacency_matrix(mat_cnt,mode='undirected',weighted=TRUE)
plot(gr,edge.width=log(E(gr)$weight))
#Use ConContext for randomization Analysis
doe_rand <- conContext(doephas,var=c('pForest','dist'),nrand=1000)
g1 = ggplot(doe_rand, aes(x=dt_lev, y=pForest)) +
geom_boxplot() +
labs(x='',y='Forest Cover (%)')
g2 = ggplot(doe_rand, aes(x=dt_lev, y=dist)) +
geom_boxplot() +
labs(x='',y='Step-Length (m)')
g1
g2
tapply(doe_rand$dist, doe_rand$dt_lev, mean)
tapply(doe_rand$dist, doe_rand$dt_lev, sd)
tapply(doe_rand$pForest, doe_rand$dt_lev, mean)
tapply(doe_rand$pForest, doe_rand$dt_lev, sd)
m1 = lme(pForest ~ dt_lev,random = ~1|ID, data = doe_rand)
summary(m1)
e
m2 = lme(dist ~ dt_lev, random= ~1|ID, data = doe_rand)
m2
summary(m2)
?lme
m2 = lme(dist ~ dt_lev, random= ~1|ID, data = doe_rand ,na.action=na.exclude)
summary(m2)
library(sf)
devtools::install_github('jedalong/wildlifeDI')
#test on Local machine using devtools
devtools::check()
setwd('D:/RPackages/wildlifeDI/wildlifeDI/')
#test on Local machine using devtools
devtools::check()
#test on Local machine using devtools
devtools::check()
#test on Local machine using devtools
devtools::check()
devtools::check_win_release()
devtools::release_checks()
#test building on win-builder development version
devtools::check_win_devel()
#Testing building on Rhub (windows server and two Linux versions)
devtools::check_rhub()
## BUILD A TAR.GZ for local machine
a4 <- paste('R CMD check --as-cran ',pckg,'_',version,'.tar.gz',sep='')
## BUILD A TAR.GZ for local machine
pckg = 'wildlifeDI'
version = '0.4.1'
a4 <- paste('R CMD check --as-cran ',pckg,'_',version,'.tar.gz',sep='')
system(a4)
## BUILD A TAR.GZ for local machine
pckg = 'wildlifeDI'
a2 <- paste('R CMD build',pckg)
system(a2)
## BUILD A TAR.GZ for local machine
setwd('D:/RPackages/wildlifeDI')
pckg = 'wildlifeDI'
a2 <- paste('R CMD build',pckg)
system(a2)
#Submission to CRAN
setwd('D:/RPackages/wildlifeDI/wildlifeDI/')
devtools::release()
#Submission to CRAN
setwd('D:/RPackages/wildlifeDI/wildlifeDI/')
devtools::release()
#Compute data for dashboard
library(ggplot2)
library(dplyr)
library(sf)
library(gridExtra)
library(reshape2)
library(tidyverse)
df1 = read.csv('D:/COVID_19/Data/ADA_Mobility_2020_01_12.csv')
df2 = read.csv('D:/COVID_19/Data/ADA_Mobility_2021_01_03.csv')
df3 = read.csv('D:/COVID_19/Data/ADA_Mobility_2021_04_04.csv')
df4 = read.csv('D:/COVID_19/Data/ADA_Mobility_2021_04_04.csv')
df = rbind(df1,df2,df3,df4)
#Clean data
df = df[df$n_RoG > 99,]
nmax = max(df$jDay)
df_count = df %>%
group_by(ADAUID) %>%
summarise(n = n()) %>%
as.data.frame()
ada_keep = df_count$ADAUID[which(df_count$n == nmax)]
df = df[df$ADAUID %in% ada_keep,]
#Day of week
nday = max(df$jDay)
df3 = df[order(df$ADAUID,df$jDay),]
#January 1 is a wednesday
df3$DoW = factor(rep(c('We','Th','Fr','Sa','Su','Mo','Tu'),length=nday))
#Compute Baseline to February data
bl_rec = subset(df3, jDay > 31 & jDay < 61) %>%
group_by(ADAUID,DoW) %>%
select(ADAUID,DoW,avg_h_RoG,avg_TotalDur,avg_d_shannon) %>%
summarise_all(mean)
df_bl <- left_join(df3, bl_rec,by = c('ADAUID', 'DoW'))
df_bl$bl_avg_h_RoG = df_bl$avg_h_RoG.x/df_bl$avg_h_RoG.y * 100
df_bl$bl_avg_TotalDur = df_bl$avg_TotalDur.x/df_bl$avg_TotalDur.y * 100
df_bl$bl_avg_d_shannon = df_bl$avg_d_shannon.x/df_bl$avg_d_shannon.y * 100
df_bl = df_bl[,c('ADAUID','jDay','bl_avg_h_RoG','bl_avg_TotalDur','bl_avg_d_shannon')]
#dates are in Day of Year format
# Mar 17, Ontario State of Emergency
# Apr 13, week in April at height of lockdown
# May 20, Stage 1
# Jun 12, Stage 2 for much of ontario
# Jul 17, Stage 3 for much of ontario
# Aug 10, week in August at height of summer mobility
# Sep 14, week when schools started opening
# Oct 10, Day Toronto went back into Stage 2
# Nov 18, Day Toronto went into Lockdown
#days_vec = c(77-12, 104, 141, 164, 199, 223, 258, 291, 316)
#Instead lets do every week starting on Monday January 6th
days_vec = seq(6,nday,by=7)
chng_fun = function(df_bl, jjDay){
chg_df = subset(df_bl,jDay > jjDay & jDay < (jjDay+8))
chg_df = chg_df %>%
group_by(ADAUID) %>%
summarise_all(mean)
return(chg_df)
}
small_df = data.frame(NULL)
for (day in days_vec){
temp_df = chng_fun(df_bl,jjDay = day)
temp_df$jDay = day
small_df = rbind(small_df,temp_df)
}
small_df = melt(small_df,id.vars=c('ADAUID','jDay'))
write.csv(small_df,'D:/Covid_19/Data/DataForDashboard - 2021-06-16.csv')
nmax
max(df$jDay)
summary(df)
summary(df1)
summary(df2)
summary(df3)
summary(df4)
df1 = read.csv('D:/COVID_19/Data/ADA_Mobility_2020_01_12.csv')
df2 = read.csv('D:/COVID_19/Data/ADA_Mobility_2021_01_03.csv')
df3 = read.csv('D:/COVID_19/Data/ADA_Mobility_2021_04_04.csv')
df4 = read.csv('D:/COVID_19/Data/ADA_Mobility_2021_04_04.csv')
df = rbind(df1,df2,df3,df4)
df1 = read.csv('D:/COVID_19/Data/ADA_Mobility_2020_01_12.csv')
df2 = read.csv('D:/COVID_19/Data/ADA_Mobility_2021_01_03.csv')
df3 = read.csv('D:/COVID_19/Data/ADA_Mobility_2021_04_04.csv')
df4 = read.csv('D:/COVID_19/Data/ADA_Mobility_2021_05_05.csv')
df = rbind(df1,df2,df3,df4)
summary(df2)
summary(df2)
summary(df3)
summary(df4)
df = rbind(df1,df2,df3,df4)
summary(df)
#Clean data
df = df[df$n_RoG > 99,]
nmax = max(df$jDay)
nmax
df_count = df %>%
group_by(ADAUID) %>%
summarise(n = n()) %>%
as.data.frame()
ada_keep = df_count$ADAUID[which(df_count$n == nmax)]
df = df[df$ADAUID %in% ada_keep,]
#Day of week
nday = max(df$jDay)
df3 = df[order(df$ADAUID,df$jDay),]
#January 1 is a wednesday
df3$DoW = factor(rep(c('We','Th','Fr','Sa','Su','Mo','Tu'),length=nday))
#Compute Baseline to February data
bl_rec = subset(df3, jDay > 31 & jDay < 61) %>%
group_by(ADAUID,DoW) %>%
select(ADAUID,DoW,avg_h_RoG,avg_TotalDur,avg_d_shannon) %>%
summarise_all(mean)
df_bl <- left_join(df3, bl_rec,by = c('ADAUID', 'DoW'))
df_bl$bl_avg_h_RoG = df_bl$avg_h_RoG.x/df_bl$avg_h_RoG.y * 100
df_bl$bl_avg_TotalDur = df_bl$avg_TotalDur.x/df_bl$avg_TotalDur.y * 100
df_bl$bl_avg_d_shannon = df_bl$avg_d_shannon.x/df_bl$avg_d_shannon.y * 100
df_bl = df_bl[,c('ADAUID','jDay','bl_avg_h_RoG','bl_avg_TotalDur','bl_avg_d_shannon')]
# Apr 13, week in April at height of lockdown
# May 20, Stage 1
# Jun 12, Stage 2 for much of ontario
# Jul 17, Stage 3 for much of ontario
# Aug 10, week in August at height of summer mobility
# Sep 14, week when schools started opening
# Oct 10, Day Toronto went back into Stage 2
# Nov 18, Day Toronto went into Lockdown
#days_vec = c(77-12, 104, 141, 164, 199, 223, 258, 291, 316)
#Instead lets do every week starting on Monday January 6th
days_vec = seq(6,nday,by=7)
chng_fun = function(df_bl, jjDay){
chg_df = subset(df_bl,jDay > jjDay & jDay < (jjDay+8))
chg_df = chg_df %>%
group_by(ADAUID) %>%
summarise_all(mean)
return(chg_df)
}
small_df = data.frame(NULL)
for (day in days_vec){
temp_df = chng_fun(df_bl,jjDay = day)
temp_df$jDay = day
small_df = rbind(small_df,temp_df)
}
small_df = melt(small_df,id.vars=c('ADAUID','jDay'))
write.csv(small_df,'D:/Covid_19/Data/DataForDashboard - 2021-06-16.csv')
jday =unique(small_df$jDay)
jday
d1 = as.date('2020-01-06')
library(lubridate)
d1 = as.date('2020-01-06')
d1 = date('2020-01-06')
dates = seq(from=d1,by=7,length.out=length(jday))
dates
jday = max(small_df$jDay)
d1 = date('2020-01-01')
dates = seq(from=d1,by=1,length.out=length(jday))
#Fix formatting of small_df for export
#1. Turn jDay in to day of week
jday = max(small_df$jDay)
d1 = date('2020-01-01')
dates = seq(from=d1,by=1,length.out=length(jday))
length(dates)
dates
dates = seq(from=d1,by=1,length.out=nday)
#Fix formatting of small_df for export
#1. Turn jDay in to day of week
nday = max(small_df$jDay)
d1 = date('2020-01-01')
dates = seq(from=d1,by=1,length.out=nday)
summary(dates)
small_df$week = dates[small_df$jDay]
head(small_df)
levels(small_df$variable)
#2. Rename variables to something more intuitive
levels(small_df$variable) <- c('ROG','TOH','DIV')
#3. Fix up the data
share_df = small_df[,c('ADAUID','week','variable','value')]
write.csv(share_df,'D:/Covid_19/Data/DashboardExport - 2020-01_2021-05.csv')
head(share_df)
write.csv(share_df,'D:/Covid_19/Data/DashboardExport - 2020-01_2021-05.csv',
row.names = FALSE)
